{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0426352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 6_27_105333: 854it [02:56,  4.83it/s]\n",
      "Processing 7_17_203144: 486it [01:43,  4.71it/s]\n",
      "Processing 7_19_203714: 658it [02:20,  4.70it/s]\n",
      "Processing 7_1_110654: 572it [02:02,  4.67it/s]\n",
      "Processing 7_20_204009: 403it [01:23,  4.81it/s]\n",
      "Processing 7_24_205049: 431it [01:26,  5.00it/s]\n",
      "Processing 7_26_205537: 626it [01:53,  5.53it/s]\n",
      "Processing 7_7_200719: 802it [02:41,  4.95it/s]\n",
      "Processing S-7273-20_1683397172: 604it [01:54,  5.27it/s]\n",
      "Processing S-7364-20_1683396862: 332it [01:20,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ WSI Preprocessing Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import morphology\n",
    "from tqdm import tqdm\n",
    "\n",
    "WSI_DIR = \"dataset/dataset/HPV\"\n",
    "OUTPUT_PATCHES_DIR = \"output_patches/\"\n",
    "EXCEL_FILE = \"hpv_labels.xlsx\"\n",
    "PATCH_SIZE = 1024\n",
    "\n",
    "os.makedirs(OUTPUT_PATCHES_DIR, exist_ok=True)\n",
    "\n",
    "def load_hpv_labels(excel_path):\n",
    "    if os.path.exists(excel_path):\n",
    "        df = pd.read_excel(excel_path)\n",
    "        labels = dict(zip(df['slide_name'], df['hpv_status']))\n",
    "        return labels\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_tissue_coords(slide, patch_size, downscale_factor=16):\n",
    "    thumbnail = slide.get_thumbnail((slide.dimensions[0] // downscale_factor, slide.dimensions[1] // downscale_factor))\n",
    "    grayscale = rgb2gray(np.array(thumbnail))\n",
    "    thresh = threshold_otsu(grayscale)\n",
    "    binary_mask = grayscale < thresh\n",
    "    binary_mask = morphology.remove_small_objects(binary_mask, min_size=500)\n",
    "\n",
    "    tissue_coords = []\n",
    "    mask_h, mask_w = binary_mask.shape\n",
    "\n",
    "    for i in range(0, mask_w - patch_size // downscale_factor, patch_size // downscale_factor):\n",
    "        for j in range(0, mask_h - patch_size // downscale_factor, patch_size // downscale_factor):\n",
    "            patch_mask = binary_mask[j:j + patch_size // downscale_factor, i:i + patch_size // downscale_factor]\n",
    "            if np.sum(patch_mask) > 0.1 * patch_mask.size:\n",
    "                x = i * downscale_factor\n",
    "                y = j * downscale_factor\n",
    "                tissue_coords.append((x, y))\n",
    "\n",
    "    return tissue_coords\n",
    "\n",
    "def extract_patches_generator(slide_path, slide_name, labels=None, patch_size=PATCH_SIZE):\n",
    "    slide = openslide.OpenSlide(slide_path)\n",
    "    coords = get_tissue_coords(slide, patch_size)\n",
    "\n",
    "    label = labels.get(slide_name, \"Unknown\") if labels else None\n",
    "\n",
    "    for (x, y) in coords:\n",
    "        patch = slide.read_region((x, y), 0, (patch_size, patch_size)).convert(\"RGB\")\n",
    "        patch_np = np.array(patch)\n",
    "        if np.mean(patch_np) < 230:\n",
    "            yield patch_np, slide_name, x, y, label\n",
    "\n",
    "def save_patch(patch_np, slide_name, x, y, label, count, save_dir=OUTPUT_PATCHES_DIR):\n",
    "    target_dir = os.path.join(save_dir, f\"HPV_{label}\" if label else \"All\")\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    fname = f\"{slide_name}_patch_{count}\"\n",
    "    if label:\n",
    "        fname += f\"_HPV_{label}\"\n",
    "    fname += \".png\"\n",
    "    patch_path = os.path.join(target_dir, fname)\n",
    "    cv2.imwrite(patch_path, cv2.cvtColor(patch_np, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "hpv_labels = load_hpv_labels(EXCEL_FILE)\n",
    "wsi_files = [f for f in os.listdir(WSI_DIR) if f.endswith(\".svs\")]\n",
    "\n",
    "for wsi in wsi_files:\n",
    "    slide_name = os.path.splitext(wsi)[0]\n",
    "    count = 0\n",
    "    for patch_np, slide_name, x, y, label in tqdm(\n",
    "        extract_patches_generator(os.path.join(WSI_DIR, wsi), slide_name, labels=hpv_labels),\n",
    "        desc=f\"Processing {slide_name}\"\n",
    "    ):\n",
    "        save_patch(patch_np, slide_name, x, y, label, count)\n",
    "        count += 1\n",
    "\n",
    "print(\"✅ WSI Preprocessing Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cdf01eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5768"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = os.listdir('output_patches/All')\n",
    "len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51e9256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [21:26<00:00,  4.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "IMAGE_DIR = \"output_patches/All\"\n",
    "OUTPUT_DIR = \"clustered_data\"\n",
    "# OUTPUT_DIR = \"output\"\n",
    "# MODEL_NAME = \"resnet\"\n",
    "MODEL_NAME = \"efficientnet\"\n",
    "IMAGE_SIZE = (512, 512)\n",
    "\n",
    "if MODEL_NAME == \"resnet\":\n",
    "    base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling='avg')\n",
    "    preprocess = resnet_preprocess\n",
    "elif MODEL_NAME == \"efficientnet\":\n",
    "    base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, pooling='avg')\n",
    "    preprocess = efficientnet_preprocess\n",
    "else:\n",
    "    raise ValueError(\"Unsupported model\")\n",
    "\n",
    "image_paths = [os.path.join(IMAGE_DIR, fname) for fname in os.listdir(IMAGE_DIR) if fname.endswith(\".png\")]\n",
    "features = []\n",
    "valid_paths = []\n",
    "\n",
    "for path in tqdm(image_paths):\n",
    "    try:\n",
    "        img = image.load_img(path, target_size=IMAGE_SIZE)\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess(img_array)\n",
    "        feature = base_model.predict(img_array, verbose=0)\n",
    "        features.append(feature[0])\n",
    "        valid_paths.append(path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {path}: {e}\")\n",
    "\n",
    "features = np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aedfed07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05471035, -0.08890644, -0.04283147, ..., -0.05659637,\n",
       "        -0.0668222 , -0.02000637],\n",
       "       [-0.1071095 , -0.10361651, -0.00935431, ..., -0.05735889,\n",
       "        -0.09221352,  0.15958616],\n",
       "       [-0.08441477, -0.09381215,  0.23475213, ..., -0.04244846,\n",
       "        -0.08819544,  0.13114902],\n",
       "       ...,\n",
       "       [ 0.00948013,  0.37763914,  0.00478341, ..., -0.1009889 ,\n",
       "        -0.08931585,  0.00726312],\n",
       "       [-0.07154578, -0.06626318, -0.00125617, ..., -0.07764931,\n",
       "         0.01026511, -0.09862373],\n",
       "       [-0.02642258,  0.43536416, -0.12733597, ..., -0.1228595 ,\n",
       "        -0.04735574, -0.08844389]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50dcd635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5768 feature vectors to 'features.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "FEATURES_FILE = \"features.pkl\"\n",
    "\n",
    "with open(FEATURES_FILE, \"wb\") as f:\n",
    "    pickle.dump((features, valid_paths), f)\n",
    "\n",
    "print(f\"Saved {len(features)} feature vectors to '{FEATURES_FILE}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c050c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "features_normalized = normalize(features, norm='l2')\n",
    "# features_normalized = normalize(features)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "labels = kmeans.fit_predict(features_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673f72ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering complete. Images saved to respective cluster directories.\n"
     ]
    }
   ],
   "source": [
    "cluster_dirs = [os.path.join(OUTPUT_DIR, f\"cluster_{i}\") for i in range(2)]\n",
    "for d in cluster_dirs:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "for path, label in zip(valid_paths, labels):\n",
    "    fname = os.path.basename(path)\n",
    "    shutil.copy(path, os.path.join(cluster_dirs[label], fname))\n",
    "\n",
    "print(\"Clustering complete. Images saved to respective cluster directories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26bcc243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(kmeans, 'classifier_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382efda3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e904a6c4",
   "metadata": {},
   "source": [
    "# Test Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fdc9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image_path = r\"output_patches\\All\\6_27_105333_patch_0.png\"\n",
    "\n",
    "test_image_path = \"test data/human-papilloma-virus-infectio.png\"\n",
    "IMAGE_SIZE = (512, 512)\n",
    "\n",
    "features = []\n",
    "try:\n",
    "    img = image.load_img(test_image_path, target_size=IMAGE_SIZE)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess(img_array)\n",
    "    feature = base_model.predict(img_array, verbose=0)\n",
    "    features.append(feature[0])\n",
    "    valid_paths.append(path)\n",
    "except Exception as e:\n",
    "    print(f\"Error processing {path}: {e}\")\n",
    "\n",
    "features = np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c361e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "loaded_model = joblib.load('classifier_model.pkl')\n",
    "\n",
    "new_data_normalized = normalize(features, norm='l2')\n",
    "predicted_labels = loaded_model.predict(new_data_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "183ad316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb15b6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
